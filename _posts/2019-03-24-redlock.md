---
layout:     post
title:      "Redis分布式锁之Redlock"
date:       2019-03-24 12:00:00 +0800
author:     "Sky丶Memory"
header-img: "img/2019-03-24-01-bg.jpg"
tags: Storage Redis




---

在分布式中，有时偶尔需要同步或互斥不同机器上的线程，这时往往就需要一个锁服务来提供类似单机的锁功能。之前自己用的一直是单实例方式，也没有仔细思考过这个问题，最近工作中需要用到它，所以整理了下相关的知识。

关于锁服务，其应有如下特点：

- **安全性**：在任意一个时刻，至多只有一个客户端可以获得锁（**排它性**）。
- **避免死锁**：客户端最终一定可以获得锁，即便获得锁的客户端未释放之前崩溃或网络不可达。
- **容错性**：只要锁服务集群中大多数节点存活，客户端就能进行正常的申请、释放锁操作。

#### 单实例

在Redis中，常见的一种分布式锁的做法为：

```lua
 SET resource_name my_random_value NX PX 30000
```

**SET**命令中的**NX**选项表明**resource_name**不存在时，才会执行对应的命令，由于Redis是单线程，命令是串化执行，故只会存在一个客户端执行成功，其余失败。

**my_random_value**为一个全局唯一的标识，其主要作用在于关联获得锁的客户端信息，后续客户端在释放锁时，比对该值是否一致来决定是否需要删除对应的锁。

释放锁一般通过lua脚本来实现：

```lua
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end
```

可能有的人不太明白为啥这个地方不通过**del**命令直接删除，考虑如下场景：

- 客户端A获得锁，锁租约时间为x秒
- 客户端A释放锁时，没有及时到达Redis
- 锁的过期时间到了，Redis释放了锁
- 客户端B申请获取到锁
- 客户端A释放锁请求命令到达，释放了对应的锁
- 客户端C申请获取到锁，此时客户端B、C同时拥有锁，**违背了锁的互斥排它性**

在获取锁时，关联上对应客户端的信息，释放时通过类似**CAS**(**C**heck **A**nd **S**et)的思想可以避免上述问题。

关于**my_random_value**，官方推荐的做法是从/dev/urandom随机生成20字节，也可自行定义，保证唯一性即可。

另外，可能有的人依然会存在疑问，即便这样，也没有办法保证开篇提到的**安全性**，脑补一个典型的场景：

- 客户端A获取到锁
- 其他客户端等待A的工作完成
- 客户端A由于卡在一些事情上，比如某个外部调用突然变得很慢、碰上了Full GC等，花费的时间是平时的几倍
- 锁的过期时间到了，Redis释放了锁
- 此时，其他客户端可申请获取锁，假设客户端B获取到了锁，这个时候，有可能客户端A还没缓过神来执行需要互斥或同步的操作，这样B和C就同时拥有了锁，违背了互斥排它性

首先，这种场景肯定是存在的，但这并不是分布式锁服务的问题，而是**trade-off**的问题，为什么这么说呢？

对于锁服务来说，由于需要保证**避免死锁**，所以一定会在一个有限的时间内清理掉未曾释放的锁，对获取到这些未曾释放锁的客户端来说，当锁的租约时间到达时，其释放锁的操作可能在网络上、也可能还未发起、也有可能该客户端已经挂掉等。

此时，对于锁服务来说需要考虑当前情况下决策应该怎么做，最简单的方式莫过于一刀切，即直接释放锁，由业务方自行解决。

一般我的用法是申请、释放锁时，记录对应的操作状态，类似一个简单对账功能，便于排查问题：

```python
import logging
import base64
import os
import time

import redis

logger = logging.getLogger(__name__)


class DLock:
    _unlock_script = """
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end
    """

    def __init__(self, client):
        self.client = client

    def lock(self, key, val, ex):
        locked = self.client.set(key, val, ex=ex, nx=True)
        logger.info('key:{key}\tval:{val}\tex:{ex}\tlocked:{locked}'.format(key=key, val=base64.b64encode(val), ex=ex, locked=bool(locked)))
        return locked

    def unlock(self, key, val):
        unlocked = self.client.eval(self._unlock_script, 1, key, val)
        logger.info('key:{key}\tval:{val}\tunlocked:{unlocked}'.format(key=key, val=base64.b64encode(val), unlocked=bool(unlocked)))
        return unlocked


def test():
    random_val = os.urandom(20)
    client = redis.StrictRedis()
    dlm = DLock(client)
    if not dlm.lock('mutex', random_val, 5):
        return
    try:
        print("Hello,world")
        time.sleep(3)
    finally:
        dlm.unlock('mutex', random_val)


if __name__ == '__main__':
    test()

```



#### 基于故障转移

单实例面临单点故障问题，从提升服务可用性的角度，我们自然而然会想到通过故障转移来尽可能提升服务可用性。

Redis的复制模式为异步方式，主从之间可达到最终一致性，针对异步复制模式，不难脑补一种场景：

- 客户端A通过master节点获取到锁
- master在广播该写操作给从节点前宕机
- 从节点提升为master节点
- 客户端B从新的master获取到锁，此时，客户端A、B都持有锁，**违背了安全性**

所以，基于故障转移的方案也不太靠谱。

#### Redlock

Redlock是Redis作者基于Redis实现的一个分布式锁服务算法，在Redlock中，每个节点都是完全独立的，这意味着每个节点都不需要和其他节点通信，另外，在每个节点申请、释放锁的操作与单实例版类似，不做过多叙述。

这里，假设集群中节点个数为5，客户端与各节点交互如下所示：

![](/img/2019-03-24-01-01.jpg)

客户端获取锁的步骤：

- 获取客户端当前时间T1
- 在A到E节点顺序获取锁，对每个节点获取锁的过程中，需要指定明确的超时时间，避免和其中某个已经挂掉的节点进行长时间交互
- 客户端当前时间为T2，客户端计算获取锁消耗的时间粗略假设为T2-T1，当且仅当客户端获取到集群中超过半数节点的锁（例子中至少为三个节点）并且T2-T1远远小于锁的有效时间（即TTL），该客户端才可认为拥有该锁
- 如果客户端获取锁失败（没有半数节点或T2-T1不满足条件），客户端尝试释放所有节点的锁

我们从安全性、可用性角度来验证下算法的正确性。

##### 安全性

首先，Redlock中定义客户端获取到锁的前提条件是：获得超过半数节点的锁及客户端所消耗时间远小于TTL。

为什么需要客户端消耗时间远小于TTL呢？很简单，为了保证获得超过半数节点的锁这个信息是**可靠的**，因为这里面会存在一种情形：在进行后续节点申请锁时，之前节点已经获取到的锁租约时间到了，所以必须要保证在申请分布式锁的这个时间窗口内，节点获取到的锁未过期。

![](/img/2019-03-24-01-02.jpg)

上图大致展示了客户端与各个节点交互时序图，仔细思考这个过程，会发现一个有意思的问题，当客户端得出已经获取到超过大多数节点的锁这个信息时，保证这个信息的可靠性，只需要知道**客户端第一个获得锁节点的租约时间是否到期即可**

假设第一个成功设置锁节点时间为T1（开始连接该节点前时间），最后一个成功设置锁节点时间为 T2，那对于第一个节点有效剩余时间为 ***MIN_VALIDITY=TTL-(T2-T1)-CLOCK_DRIFT***，**CLOCK_DRIFT**为时间漂移。

所以保证信息的可靠性可以根据上述公式得出，这两个限制条件已经能保证安全性。

##### 可用性

- 过期时间保证了锁最终一定会释放
- 当客户端获取锁失败时，会释放占有的资源并进行重试

初看这部分时，会发现涉及到多资源分配问题，就有可能会产生死锁，不过，客户端获取锁失败时，**释放占有的资源**，这点很关键，破坏了形成死锁的必要条件之一—**请求和保持条件**，所以可用性上也没有问题（但个人感觉这里面有概率问题？？）。

最后，关于Redlock，大部分语言都有对应的实现，可以尝试看下熟悉语言对应实现大概就明白了。



#### 参考文档

[Distributed locks with Redis](https://redis.io/topics/distlock)